#!/usr/bin/env python3
"""
ğŸš€ TESTE RÃPIDO DO SISTEMA MULTI-LLM
====================================

Este script testa rapidamente se o sistema Multi-LLM estÃ¡ funcionando corretamente.
Execute: python quick_test.py
"""

import os
import sys
import asyncio
from pathlib import Path

# Adicionar o src ao path
sys.path.insert(0, str(Path(__file__).parent / "src"))

async def test_system():
    """Teste rÃ¡pido do sistema Multi-LLM"""
    print("ğŸ” Testando Sistema Multi-LLM Database RAG...")
    print("=" * 50)
    
    try:
        # Importar e criar sistema
        from multi_llm_rag_system import create_multi_llm_rag_system_from_env
        
        print("âœ“ MÃ³dulos importados com sucesso")
        
        # Verificar variÃ¡veis de ambiente
        print("\nğŸ“‹ Verificando configuraÃ§Ã£o...")
        
        # Verificar provedores configurados
        providers_found = []
        
        # OpenAI
        if os.getenv("OPENAI_API_KEY"):
            providers_found.append("OpenAI")
            print("âœ“ OpenAI configurado")
        else:
            print("âš ï¸ OpenAI nÃ£o configurado (OPENAI_API_KEY ausente)")
        
        # Ollama
        if os.getenv("OLLAMA_MODEL") and os.getenv("OLLAMA_BASE_URL"):
            providers_found.append("Ollama")
            print("âœ“ Ollama configurado")
        else:
            print("âš ï¸ Ollama nÃ£o configurado")
        
        # Custom
        if os.getenv("CUSTOM_LLM_API_BASE") and os.getenv("CUSTOM_LLM_MODEL"):
            providers_found.append("Custom")
            print("âœ“ API Customizada configurada")
        else:
            print("âš ï¸ API Customizada nÃ£o configurada")
        
        if not providers_found:
            print("âŒ Nenhum provedor configurado!")
            print("\nğŸ“– Configure pelo menos um provedor no arquivo .env:")
            print("   1. Copie .env.multi-llm.example para .env")
            print("   2. Configure pelo menos um provedor (OpenAI, Ollama ou Custom)")
            print("   3. Execute novamente este teste")
            return False
        
        print(f"\nğŸ¯ Provedores encontrados: {', '.join(providers_found)}")
        
        # Criar sistema RAG
        print("\nğŸ¤– Inicializando sistema RAG...")
        rag_system = create_multi_llm_rag_system_from_env()
        
        if not rag_system:
            print("âŒ Falha ao criar sistema RAG")
            return False
        
        print("âœ“ Sistema RAG criado")
        
        # Tentar inicializar
        print("ğŸ”§ Inicializando provedores...")
        if not rag_system.initialize():
            print("âŒ Falha ao inicializar sistema")
            return False
        
        print("âœ“ Sistema inicializado com sucesso")
        
        # Verificar status do sistema
        print("\nğŸ“Š Status do sistema:")
        status = rag_system.get_system_info()
        
        for provider_type, providers in status.get("providers", {}).items():
            print(f"  {provider_type}:")
            for name, info in providers.items():
                status_icon = "âœ…" if info.get("available") else "âŒ"
                active_icon = "ğŸ”¥" if info.get("active") else "ğŸ’¤"
                print(f"    {status_icon}{active_icon} {name}: {info}")
        
        # Teste simples de query (se banco existir)
        print("\nğŸ§ª Testando consulta simples...")
        
        try:
            # Query de teste que nÃ£o depende do banco de dados especÃ­fico
            test_query = "Como posso usar este sistema?"
            print(f"Pergunta: '{test_query}'")
            
            result = rag_system.query(test_query)
            
            if result and result.get("answer"):
                print("âœ… Consulta processada com sucesso!")
                print(f"ğŸ“ Resposta: {result['answer'][:200]}...")
                if result.get("provider_used"):
                    print(f"ğŸ¤– Provedor usado: {result['provider_used']}")
            else:
                print("âš ï¸ Consulta processada mas sem resposta clara")
                
        except Exception as e:
            print(f"âš ï¸ Erro na consulta de teste: {e}")
            print("   (Isso pode ser normal se nÃ£o hÃ¡ banco de dados configurado)")
        
        print("\nğŸ‰ Teste completado com sucesso!")
        print("\nğŸ“š PrÃ³ximos passos:")
        print("   1. Configure seu banco de dados")
        print("   2. Execute: python multi_llm_api.py")
        print("   3. Teste via API: http://localhost:9000/docs")
        
        return True
        
    except ImportError as e:
        print(f"âŒ Erro de importaÃ§Ã£o: {e}")
        print("\nğŸ”§ PossÃ­veis soluÃ§Ãµes:")
        print("   1. Instale as dependÃªncias: pip install -r requirements.txt")
        print("   2. Verifique se estÃ¡ no diretÃ³rio correto")
        return False
        
    except Exception as e:
        print(f"âŒ Erro inesperado: {e}")
        return False


def main():
    """FunÃ§Ã£o principal"""
    print("ğŸš€ Teste RÃ¡pido - Sistema Multi-LLM Database RAG")
    print("=" * 50)
    
    # Verificar se arquivo .env existe
    if not os.path.exists(".env"):
        print("âš ï¸ Arquivo .env nÃ£o encontrado!")
        print("\nğŸ“‹ Para configurar:")
        print("   1. cp .env.multi-llm.example .env")
        print("   2. Edite .env com suas configuraÃ§Ãµes")
        print("   3. Execute novamente este teste")
        return
    
    # Carregar variÃ¡veis de ambiente do .env
    try:
        from dotenv import load_dotenv
        load_dotenv()
        print("âœ“ Arquivo .env carregado")
    except ImportError:
        print("âš ï¸ python-dotenv nÃ£o instalado")
        print("   Instale com: pip install python-dotenv")
        # Continua mesmo assim, caso as vars estejam no ambiente
    
    # Executar teste
    if asyncio.run(test_system() if asyncio.iscoroutinefunction(test_system) else asyncio.coroutine(test_system)()):
        print("\nâœ… Sistema Multi-LLM estÃ¡ funcionando!")
    else:
        print("\nâŒ Problemas encontrados no sistema")
        sys.exit(1)


if __name__ == "__main__":
    main()
