#!/usr/bin/env python3
"""
Teste de carregamento de variÃ¡veis .env pelo sistema Multi-LLM
"""
import os
import sys

# Add src to path - ajustado para nova estrutura
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "src"))

from multi_llm_rag_system import create_multi_llm_rag_system_from_env
from config_multi_llm import MultiLLMConfig

def test_env_loading():
    """Testa se as variÃ¡veis do .env estÃ£o sendo carregadas"""
    print("ğŸ” TESTE DE CARREGAMENTO DO ARQUIVO .ENV")
    print("=" * 50)
    
    # Teste 1: Verificar se as variÃ¡veis estÃ£o no environment
    print("\nğŸ“‹ 1. VARIÃVEIS DO SISTEMA:")
    key_vars = [
        "OPENAI_API_KEY", "OLLAMA_BASE_URL", "OLLAMA_MODEL", 
        "DATABASE_URL", "DATABASE_PATH", "PREFERRED_LLM_PROVIDER"
    ]
    
    for var in key_vars:
        value = os.getenv(var)
        if value:
            # Mascarar chaves sensÃ­veis
            if "API_KEY" in var:
                display_value = f"{value[:10]}***{value[-4:]}" if len(value) > 14 else "***"
            else:
                display_value = value
            print(f"   âœ… {var} = {display_value}")
        else:
            print(f"   âŒ {var} = (nÃ£o definida)")
    
    # Teste 2: Verificar carregamento via MultiLLMConfig
    print("\nğŸ“‹ 2. CONFIGURAÃ‡ÃƒO MULTI-LLM:")
    try:
        config = MultiLLMConfig.from_env()
        print(f"   ğŸ¤– OpenAI disponÃ­vel: {'âœ…' if config.openai else 'âŒ'}")
        print(f"   ğŸ  Ollama disponÃ­vel: {'âœ…' if config.ollama else 'âŒ'}")
        print(f"   ğŸ¢ Custom disponÃ­vel: {'âœ…' if config.custom else 'âŒ'}")
        print(f"   ğŸ“Š Total provedores: {len([p for p in [config.openai, config.ollama, config.custom] if p])}")
        
        if config.has_any_provider():
            print("   âœ… Sistema tem pelo menos um provedor configurado")
        else:
            print("   âŒ ERRO: Nenhum provedor configurado!")
            
    except Exception as e:
        print(f"   âŒ ERRO ao carregar MultiLLMConfig: {e}")
    
    # Teste 3: Verificar criaÃ§Ã£o do sistema RAG
    print("\nğŸ“‹ 3. SISTEMA RAG:")
    try:
        rag_system = create_multi_llm_rag_system_from_env()
        print("   âœ… Sistema RAG criado com sucesso")
        
        # Verificar provedores disponÃ­veis
        available_providers = rag_system.provider_manager.list_available_providers()
        print(f"   ğŸ“Š LLM providers: {len(available_providers.get('llm_providers', {}))}")
        print(f"   ğŸ“Š Embedding providers: {len(available_providers.get('embedding_providers', {}))}")
        
        for provider_name, info in available_providers.get('llm_providers', {}).items():
            status = "âœ…" if info.get('available') else "âŒ"
            print(f"      {status} {provider_name}: {info.get('reason', 'OK')}")
            
    except Exception as e:
        print(f"   âŒ ERRO ao criar sistema RAG: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "=" * 50)
    print("ğŸ TESTE CONCLUÃDO")

if __name__ == "__main__":
    test_env_loading()
